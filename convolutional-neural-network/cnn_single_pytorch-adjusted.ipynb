{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-03-27T18:21:50.199217Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 18:22:14.525095: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_filters, filter_sizes, output_dim, dropout):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(fs, embedding_dim))\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "        self.fc = nn.Linear(len(filter_sizes) * num_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)  # [batch_size, seq_len, embedding_dim]\n",
    "        embedded = embedded.unsqueeze(1)  # [batch_size, 1, seq_len, embedding_dim]\n",
    "\n",
    "        conved = [nn.functional.relu(conv(embedded)).squeeze(3) for conv in self.convs]  # [batch_size, num_filters, seq_len - filter_sizes[n] + 1]\n",
    "\n",
    "        pooled = [nn.functional.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]  # [batch_size, num_filters]\n",
    "\n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "        \n",
    "        return self.fc(cat)\n",
    "\n",
    "raw_data = pd.read_csv(\"../data/adjusted-labels-comms-exclusive.csv\")\n",
    "\n",
    "sentences = raw_data[\"Sentence\"]\n",
    "labels = raw_data[\"Label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Feature extraction\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Example, you can choose parameters as needed\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Move data to GPU\n",
    "X = X_train_tfidf.to(device)\n",
    "y = labels.to(device)\n",
    "\n",
    "# Hyperparameters\n",
    "vocab_size = 10  # Example vocabulary size\n",
    "embedding_dim = 50\n",
    "num_filters = 100\n",
    "filter_sizes = [2, 3, 4]\n",
    "output_dim = 1  # Number of classes\n",
    "dropout = 0.5\n",
    "\n",
    "# Initialize the model and move it to GPU\n",
    "model = CNN(vocab_size, embedding_dim, num_filters, filter_sizes, output_dim, dropout).to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "def train(model, X, y, optimizer, criterion, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X).squeeze(1)\n",
    "        loss = criterion(output, y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch: {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Train the model\n",
    "train(model, X, y, optimizer, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
