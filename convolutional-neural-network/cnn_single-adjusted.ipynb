{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Speech Act Classification using a CNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32472116a3a43df4"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:48:43.405564Z",
     "start_time": "2024-03-26T17:48:43.401601Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"../data/adjusted-labels-comms-exclusive.csv\")\n",
    "\n",
    "filtered_data = raw_data[raw_data[\"Label\"] != \"Other\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:48:43.446684Z",
     "start_time": "2024-03-26T17:48:43.426892Z"
    }
   },
   "id": "dd4cf236a4ccc3ca",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sentences = filtered_data[\"Sentence\"]\n",
    "labels = filtered_data[\"Label\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:48:43.459367Z",
     "start_time": "2024-03-26T17:48:43.454990Z"
    }
   },
   "id": "b60a8c57de3da7df",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentences, labels, test_size=0.2, random_state=47)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:48:43.469182Z",
     "start_time": "2024-03-26T17:48:43.461800Z"
    }
   },
   "id": "92fc8279c42e3f58",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create feature vectors\n",
    "vectorizer = TfidfVectorizer(min_df=5,\n",
    "                             max_df=0.8,\n",
    "                             sublinear_tf=True,\n",
    "                             use_idf=True)\n",
    "train_vectors = vectorizer.fit_transform(X_train)\n",
    "test_vectors = vectorizer.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:48:43.652597Z",
     "start_time": "2024-03-26T17:48:43.473837Z"
    }
   },
   "id": "962154704e54ee56",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.36271615\n",
      "Iteration 2, loss = 2.24690361\n",
      "Iteration 3, loss = 2.13885572\n",
      "Iteration 4, loss = 2.03283852\n",
      "Iteration 5, loss = 1.91124160\n",
      "Iteration 6, loss = 1.77890463\n",
      "Iteration 7, loss = 1.65111775\n",
      "Iteration 8, loss = 1.53382804\n",
      "Iteration 9, loss = 1.43137939\n",
      "Iteration 10, loss = 1.34097493\n",
      "Iteration 11, loss = 1.26341874\n",
      "Iteration 12, loss = 1.19766247\n",
      "Iteration 13, loss = 1.13927788\n",
      "Iteration 14, loss = 1.09371546\n",
      "Iteration 15, loss = 1.05237555\n",
      "Iteration 16, loss = 1.01688329\n",
      "Iteration 17, loss = 0.98737489\n",
      "Iteration 18, loss = 0.96225588\n",
      "Iteration 19, loss = 0.93953606\n",
      "Iteration 20, loss = 0.92056936\n",
      "Iteration 21, loss = 0.90240084\n",
      "Iteration 22, loss = 0.88686142\n",
      "Iteration 23, loss = 0.87451614\n",
      "Iteration 24, loss = 0.86176296\n",
      "Iteration 25, loss = 0.85264223\n",
      "Iteration 26, loss = 0.84031434\n",
      "Iteration 27, loss = 0.83123435\n",
      "Iteration 28, loss = 0.82493112\n",
      "Iteration 29, loss = 0.81813265\n",
      "Iteration 30, loss = 0.81059050\n",
      "Iteration 31, loss = 0.80496266\n",
      "Iteration 32, loss = 0.79816863\n",
      "Iteration 33, loss = 0.79284086\n",
      "Iteration 34, loss = 0.78883411\n",
      "Iteration 35, loss = 0.78546018\n",
      "Iteration 36, loss = 0.78074135\n",
      "Iteration 37, loss = 0.77698584\n",
      "Iteration 38, loss = 0.77501241\n",
      "Iteration 39, loss = 0.77156970\n",
      "Iteration 40, loss = 0.76853384\n",
      "Iteration 41, loss = 0.76436234\n",
      "Iteration 42, loss = 0.76158293\n",
      "Iteration 43, loss = 0.75989742\n",
      "Iteration 44, loss = 0.75866742\n",
      "Iteration 45, loss = 0.75763651\n",
      "Iteration 46, loss = 0.75271043\n",
      "Iteration 47, loss = 0.75185052\n",
      "Iteration 48, loss = 0.75244360\n",
      "Iteration 49, loss = 0.74753246\n",
      "Iteration 50, loss = 0.74735585\n",
      "Iteration 51, loss = 0.74372923\n",
      "Iteration 52, loss = 0.74455533\n",
      "Iteration 53, loss = 0.74302969\n",
      "Iteration 54, loss = 0.74239377\n",
      "Iteration 55, loss = 0.73990442\n",
      "Iteration 56, loss = 0.73809891\n",
      "Iteration 57, loss = 0.73863539\n",
      "Iteration 58, loss = 0.73638657\n",
      "Iteration 59, loss = 0.73506589\n",
      "Iteration 60, loss = 0.73702551\n",
      "Iteration 61, loss = 0.73502511\n",
      "Iteration 62, loss = 0.73486308\n",
      "Iteration 63, loss = 0.73258182\n",
      "Iteration 64, loss = 0.73195237\n",
      "Iteration 65, loss = 0.73091778\n",
      "Iteration 66, loss = 0.72825920\n",
      "Iteration 67, loss = 0.72988827\n",
      "Iteration 68, loss = 0.72869315\n",
      "Iteration 69, loss = 0.72876752\n",
      "Iteration 70, loss = 0.72926247\n",
      "Iteration 71, loss = 0.72713787\n",
      "Iteration 72, loss = 0.72531711\n",
      "Iteration 73, loss = 0.72453140\n",
      "Iteration 74, loss = 0.72480232\n",
      "Iteration 75, loss = 0.72397037\n",
      "Iteration 76, loss = 0.72368058\n",
      "Iteration 77, loss = 0.72318932\n",
      "Iteration 78, loss = 0.72321241\n",
      "Iteration 79, loss = 0.72222434\n",
      "Iteration 80, loss = 0.72098257\n",
      "Iteration 81, loss = 0.72078598\n",
      "Iteration 82, loss = 0.72209842\n",
      "Iteration 83, loss = 0.72003153\n",
      "Iteration 84, loss = 0.71951140\n",
      "Iteration 85, loss = 0.72022503\n",
      "Iteration 86, loss = 0.72056036\n",
      "Iteration 87, loss = 0.71911805\n",
      "Iteration 88, loss = 0.71836482\n",
      "Iteration 89, loss = 0.72208307\n",
      "Iteration 90, loss = 0.72116477\n",
      "Iteration 91, loss = 0.72088303\n",
      "Iteration 92, loss = 0.71814563\n",
      "Iteration 93, loss = 0.71869164\n",
      "Iteration 94, loss = 0.72190916\n",
      "Iteration 95, loss = 0.71899750\n",
      "Iteration 96, loss = 0.71706188\n",
      "Iteration 97, loss = 0.71627108\n",
      "Iteration 98, loss = 0.71684851\n",
      "Iteration 99, loss = 0.71595717\n",
      "Iteration 100, loss = 0.71546996\n",
      "Iteration 101, loss = 0.71626655\n",
      "Iteration 102, loss = 0.71613356\n",
      "Iteration 103, loss = 0.71498236\n",
      "Iteration 104, loss = 0.71568710\n",
      "Iteration 105, loss = 0.71562351\n",
      "Iteration 106, loss = 0.71602170\n",
      "Iteration 107, loss = 0.71465925\n",
      "Iteration 108, loss = 0.71489651\n",
      "Iteration 109, loss = 0.71340756\n",
      "Iteration 110, loss = 0.71329335\n",
      "Iteration 111, loss = 0.71282169\n",
      "Iteration 112, loss = 0.71416025\n",
      "Iteration 113, loss = 0.71404659\n",
      "Iteration 114, loss = 0.71304015\n",
      "Iteration 115, loss = 0.71306818\n",
      "Iteration 116, loss = 0.71357007\n",
      "Iteration 117, loss = 0.71250681\n",
      "Iteration 118, loss = 0.71315600\n",
      "Iteration 119, loss = 0.71358601\n",
      "Iteration 124, loss = 0.71130155\n",
      "Iteration 120, loss = 0.71323928\n",
      "Iteration 121, loss = 0.71474397\n",
      "Iteration 122, loss = 0.71346419\n",
      "Iteration 123, loss = 0.71113054\n",
      "Iteration 125, loss = 0.71139938\n",
      "Iteration 126, loss = 0.71231541\n",
      "Iteration 127, loss = 0.71146763\n",
      "Iteration 128, loss = 0.71064167\n",
      "Iteration 129, loss = 0.70992606\n",
      "Iteration 130, loss = 0.70862293\n",
      "Iteration 131, loss = 0.70985399\n",
      "Iteration 132, loss = 0.71118512\n",
      "Iteration 133, loss = 0.70987928\n",
      "Iteration 134, loss = 0.71012894\n",
      "Iteration 135, loss = 0.71159965\n",
      "Iteration 136, loss = 0.71080794\n",
      "Iteration 137, loss = 0.70936815\n",
      "Iteration 138, loss = 0.70993722\n",
      "Iteration 139, loss = 0.71053310\n",
      "Iteration 140, loss = 0.70836785\n",
      "Iteration 141, loss = 0.70991466\n",
      "Iteration 142, loss = 0.70949102\n",
      "Iteration 143, loss = 0.71131598\n",
      "Iteration 144, loss = 0.71083090\n",
      "Iteration 145, loss = 0.71395891\n",
      "Iteration 146, loss = 0.71206172\n",
      "Iteration 147, loss = 0.71180859\n",
      "Iteration 148, loss = 0.71111021\n",
      "Iteration 149, loss = 0.70929482\n",
      "Iteration 150, loss = 0.70819613\n",
      "Iteration 151, loss = 0.71143275\n",
      "Iteration 152, loss = 0.70913663\n",
      "Iteration 153, loss = 0.70833954\n",
      "Iteration 154, loss = 0.70830412\n",
      "Iteration 155, loss = 0.71037314\n",
      "Iteration 156, loss = 0.70818303\n",
      "Iteration 157, loss = 0.71121340\n",
      "Iteration 158, loss = 0.70726670\n",
      "Iteration 159, loss = 0.70883107\n",
      "Iteration 160, loss = 0.70963228\n",
      "Iteration 161, loss = 0.70871014\n",
      "Iteration 162, loss = 0.70913084\n",
      "Iteration 163, loss = 0.70726311\n",
      "Iteration 164, loss = 0.70740368\n",
      "Iteration 165, loss = 0.70662075\n",
      "Iteration 166, loss = 0.70919801\n",
      "Iteration 167, loss = 0.70722204\n",
      "Iteration 168, loss = 0.70777873\n",
      "Iteration 169, loss = 0.70668307\n",
      "Iteration 170, loss = 0.70865911\n",
      "Iteration 171, loss = 0.70691745\n",
      "Iteration 172, loss = 0.70609776\n",
      "Iteration 173, loss = 0.70760154\n",
      "Iteration 174, loss = 0.70666704\n",
      "Iteration 175, loss = 0.70628641\n",
      "Iteration 176, loss = 0.70639928\n",
      "Iteration 177, loss = 0.70800270\n",
      "Iteration 178, loss = 0.70814928\n",
      "Iteration 179, loss = 0.70595194\n",
      "Iteration 180, loss = 0.70574699\n",
      "Iteration 181, loss = 0.70458297\n",
      "Iteration 182, loss = 0.70556892\n",
      "Iteration 183, loss = 0.70562343\n",
      "Iteration 184, loss = 0.70638295\n",
      "Iteration 185, loss = 0.70805527\n",
      "Iteration 186, loss = 0.70687227\n",
      "Iteration 187, loss = 0.70734941\n",
      "Iteration 188, loss = 0.70795644\n",
      "Iteration 189, loss = 0.70912161\n",
      "Iteration 190, loss = 0.70863609\n",
      "Iteration 191, loss = 0.70509703\n",
      "Iteration 192, loss = 0.70651017\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 0.28\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Action words       0.25      0.22      0.23        51\n",
      "              Buildings       0.12      0.13      0.12        78\n",
      "         Communications       0.87      0.88      0.87       113\n",
      "             Directions       0.14      0.19      0.16        21\n",
      "             Fire words       0.36      0.35      0.36       138\n",
      "      Hills and Forests       0.14      0.15      0.14        41\n",
      "Intel (from newspapers)       0.07      0.19      0.11        21\n",
      "        Named Locations       0.13      0.14      0.13       141\n",
      "        Reasoning words       0.11      0.08      0.09        51\n",
      "           Rescue words       0.26      0.14      0.18        73\n",
      "                  Woods       0.17      0.15      0.16        67\n",
      "\n",
      "               accuracy                           0.28       795\n",
      "              macro avg       0.24      0.24      0.23       795\n",
      "           weighted avg       0.29      0.28      0.29       795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(200,), max_iter=500, alpha=0.001, solver='adam', verbose=10, random_state=42, tol=0.0001)\n",
    "\n",
    "# Step 4: Training\n",
    "mlp_classifier.fit(train_vectors, y_train)\n",
    "\n",
    "# Step 5: Evaluation\n",
    "predictions = mlp_classifier.predict(test_vectors)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n",
    "print(classification_report(y_test, predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:49:12.155313Z",
     "start_time": "2024-03-26T17:48:43.655201Z"
    }
   },
   "id": "f60be536d03455ac",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:49:12.160358Z",
     "start_time": "2024-03-26T17:49:12.157650Z"
    }
   },
   "id": "dd814cc4f3c22a4c",
   "execution_count": 44
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
