{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Support Vector Machines\n",
    "Using a support vector machine to classify data based on the speech act"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87f871e05af36c7d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-07T18:31:26.355652Z",
     "start_time": "2024-02-07T18:31:26.299793Z"
    }
   },
   "id": "initial_id",
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generating the sentences and labels from the Excel sheet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4d37c3a49d99afb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences:  ['alpha, charlie. bravo check.', \"alpha you're loud_and_clear.\", 'charlie. good to me', 'charlie, charlie one, bravo radio check. ', 'yeah. charlie good to me. over']\n",
      "I have sentences:  81\n",
      "Correct Labels:  ['Request for Situation', 'Statement of Situation', 'Statement of Situation', 'Request for Situation', 'Statement of Situation', 'Statement of Situation', 'Not Classified', 'Statement of Situation', 'Statement of Situation', 'Statement of Situation', 'Statement of Action', 'Statement of Intent', 'Statement of Situation', 'Request for Situation', 'Statement of Situation', 'Statement of Situation', 'Not Classified', 'Statement of Situation', 'Statement of Situation', 'Not Classified', 'Not Classified', 'Statement of Situation', 'Statement of Prediction', 'Statement of Intent', 'Not Classified', 'Statement of Intent', 'Statement of Prediction', 'Not Classified', 'Statement of Intent', 'Statement of Prediction', 'Statement of Prediction', 'Not Classified', 'Not Classified', 'Statement of Intent', 'Statement of Prediction', 'Statement of Intent', 'Statement of Intent', 'Request for Action', 'Statement of Prediction', 'Statement of Prediction', 'Statement of Situation', 'Statement of Situation', 'Not Classified', 'Statement of Situation', 'Statement of Intent', 'Statement of Intent', 'Request for Action', 'Statement of Situation', 'Statement of Situation', 'Statement of Action', 'Statement of Intent', 'Not Classified', 'Statement of Intent', 'Statement of Intent', 'Request for Action', 'Statement of Action', 'Request for Situation', 'Statement of Situation', 'Statement of Situation', 'Statement of Intent', 'Statement of Action', 'Request for Situation', 'Statement of Situation', 'Request for Action', 'Statement of Action', 'Statement of Situation', 'Statement of Situation', 'Statement of Intent', 'Statement of Action', 'Request for Action', 'Statement of Prediction', 'Statement of Action', 'Statement of Intent', 'Request for Situation', 'Statement of Situation', 'Statement of Intent', 'Statement of Prediction', 'Statement of Situation', 'Statement of Intent', 'Statement of Action', 'Statement of Intent']\n",
      "I have labels:  81\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import get_sentences_labels\n",
    "\n",
    "sentences, labels = get_sentences_labels()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T18:31:26.396592Z",
     "start_time": "2024-02-07T18:31:26.375090Z"
    }
   },
   "id": "a45df1543cdc221a",
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing\n",
    "Vectorising the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "769e7a6349ab9aee"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(sentences)\n",
    "y = labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T18:31:26.398585Z",
     "start_time": "2024-02-07T18:31:26.389378Z"
    }
   },
   "id": "46c9a5c6479f72d7",
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "source": [
    "Encode the labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "305273d1672bc37e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T18:31:26.417680Z",
     "start_time": "2024-02-07T18:31:26.402557Z"
    }
   },
   "id": "3bb0c44bb09a0757",
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert to tensors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8efefb522af0ec20"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X = torch.tensor(X.toarray(), dtype=torch.float32)\n",
    "y = torch.tensor(y_encoded, dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T18:31:26.462735Z",
     "start_time": "2024-02-07T18:31:26.408856Z"
    }
   },
   "id": "4bb66bc5b7ab6156",
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defining the SVM model using TensorFlow"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76724653bc8d0176"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class SVM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVM, self).__init__()\n",
    "        self.linear = nn.Linear(X.shape[1], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T18:31:26.484365Z",
     "start_time": "2024-02-07T18:31:26.422624Z"
    }
   },
   "id": "70377c6f3fa22629",
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the SVM model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb0eea45e09de7b7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = SVM()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T18:31:26.506935Z",
     "start_time": "2024-02-07T18:31:26.471945Z"
    }
   },
   "id": "805aa787fbf3fa45",
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define loss function and optimiser"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41437035351fa76f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "criterion = nn.HingeEmbeddingLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T18:31:26.538863Z",
     "start_time": "2024-02-07T18:31:26.512191Z"
    }
   },
   "id": "1a2f27cd63692a7c",
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e26940cd867b74c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.9115352630615234\n",
      "Epoch [20/100], Loss: 0.891568660736084\n",
      "Epoch [30/100], Loss: 0.8716022968292236\n",
      "Epoch [40/100], Loss: 0.851635754108429\n",
      "Epoch [50/100], Loss: 0.8316693902015686\n",
      "Epoch [60/100], Loss: 0.8117028474807739\n",
      "Epoch [70/100], Loss: 0.791736364364624\n",
      "Epoch [80/100], Loss: 0.7717699408531189\n",
      "Epoch [90/100], Loss: 0.751803457736969\n",
      "Epoch [100/100], Loss: 0.7318369746208191\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs.squeeze(), y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T18:31:26.636676Z",
     "start_time": "2024-02-07T18:31:26.532677Z"
    }
   },
   "id": "976bc3f0df295f84",
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2af8d1c5b7fc5b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.12345679012345678\n",
      "Precision: 0.8747795414462082\n",
      "Recall: 0.14285714285714285\n",
      "F1-score: 0.03139717425431711\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Convert model predictions to labels\n",
    "def predictions_to_labels(predictions):\n",
    "    return torch.round(torch.sigmoid(predictions)).detach().numpy()\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    predicted_labels = predictions_to_labels(model(X))\n",
    "\n",
    "# Convert ground truth labels to numpy array\n",
    "true_labels = y.detach().numpy()\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='macro', zero_division=1)\n",
    "recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T18:31:26.652156Z",
     "start_time": "2024-02-07T18:31:26.628057Z"
    }
   },
   "id": "1d9aae0b8ac48cfd",
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "source": [
    "Decoding and evaluating with classification report"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1802b38604ed2f1b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def decode_labels(encoded_labels):\n",
    "    return label_encoder.inverse_transform(encoded_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T18:31:26.687388Z",
     "start_time": "2024-02-07T18:31:26.647348Z"
    }
   },
   "id": "286d206081139d7b",
   "execution_count": 55
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
