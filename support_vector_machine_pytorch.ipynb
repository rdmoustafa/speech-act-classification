{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Support Vector Machines\n",
    "Using a support vector machine to classify data based on the speech act"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87f871e05af36c7d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-08T16:14:30.266535Z",
     "start_time": "2024-02-08T16:14:30.164435Z"
    }
   },
   "id": "initial_id",
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generating the sentences and labels from the Excel sheet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4d37c3a49d99afb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences:  ['alpha, charlie. bravo check.', \"alpha you're loud_and_clear.\", 'charlie. good to me', 'charlie, charlie one, bravo radio check. ', 'yeah. charlie good to me. over']\n",
      "I have sentences:  70\n",
      "Correct Labels:  ['Request for Situation', 'Statement of Situation', 'Statement of Situation', 'Request for Situation', 'Statement of Situation', 'Statement of Situation', 'Not Classified', 'Statement of Situation', 'Statement of Situation', 'Statement of Situation', 'Statement of Action', 'Statement of Intent', 'Statement of Situation', 'Statement of Situation', 'Not Classified', 'Statement of Situation', 'Statement of Situation', 'Not Classified', 'Not Classified', 'Statement of Intent', 'Not Classified', 'Statement of Intent', 'Not Classified', 'Statement of Intent', 'Statement of Intent', 'Statement of Prediction', 'Not Classified', 'Not Classified', 'Statement of Intent', 'Statement of Intent', 'Statement of Intent', 'Statement of Intent', 'Statement of Prediction', 'Statement of Situation', 'Statement of Situation', 'Not Classified', 'Statement of Situation', 'Statement of Intent', 'Statement of Intent', 'Request for Action', 'Statement of Situation', 'Statement of Situation', 'Statement of Action', 'Statement of Intent', 'Not Classified', 'Statement of Intent', 'Statement of Intent', 'Request for Action', 'Statement of Action', 'Request for Situation', 'Statement of Situation', 'Statement of Situation', 'Statement of Intent', 'Statement of Action', 'Statement of Situation', 'Request for Action', 'Statement of Situation', 'Statement of Situation', 'Statement of Intent', 'Statement of Action', 'Request for Action', 'Statement of Prediction', 'Statement of Action', 'Statement of Intent', 'Request for Situation', 'Statement of Intent', 'Statement of Prediction', 'Statement of Intent', 'Statement of Action', 'Statement of Intent']\n",
      "I have labels:  70\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import get_sentences_labels\n",
    "\n",
    "# file_path = \"data/interrater_data.xlsx\"\n",
    "file_path = \"data/combined_data_set.xlsx\"\n",
    "\n",
    "sentences, labels = get_sentences_labels(file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T16:14:30.376523Z",
     "start_time": "2024-02-08T16:14:30.276112Z"
    }
   },
   "id": "a45df1543cdc221a",
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing\n",
    "Vectorising the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "769e7a6349ab9aee"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(sentences)\n",
    "y = labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T16:14:30.380359Z",
     "start_time": "2024-02-08T16:14:30.351030Z"
    }
   },
   "id": "46c9a5c6479f72d7",
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "source": [
    "Encode the labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "305273d1672bc37e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T16:14:30.434336Z",
     "start_time": "2024-02-08T16:14:30.369271Z"
    }
   },
   "id": "3bb0c44bb09a0757",
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert to tensors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8efefb522af0ec20"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X = torch.tensor(X.toarray(), dtype=torch.float32)\n",
    "y = torch.tensor(y_encoded, dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T16:14:30.490721Z",
     "start_time": "2024-02-08T16:14:30.448303Z"
    }
   },
   "id": "4bb66bc5b7ab6156",
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defining the SVM model using TensorFlow"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76724653bc8d0176"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class SVM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVM, self).__init__()\n",
    "        self.linear = nn.Linear(X.shape[1], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T16:14:30.520689Z",
     "start_time": "2024-02-08T16:14:30.500721Z"
    }
   },
   "id": "70377c6f3fa22629",
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the SVM model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb0eea45e09de7b7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = SVM()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T16:14:30.536316Z",
     "start_time": "2024-02-08T16:14:30.517299Z"
    }
   },
   "id": "805aa787fbf3fa45",
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define loss function and optimiser"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41437035351fa76f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "criterion = nn.HingeEmbeddingLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T16:14:30.553324Z",
     "start_time": "2024-02-08T16:14:30.544335Z"
    }
   },
   "id": "1a2f27cd63692a7c",
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e26940cd867b74c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not csr_matrix",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[55], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m      3\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m----> 4\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(outputs\u001B[38;5;241m.\u001B[39msqueeze(), y)\n\u001B[1;32m      6\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/Desktop/University/Year4/Final_Year_Project/Speech_Acts_Classification/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/University/Year4/Final_Year_Project/Speech_Acts_Classification/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[52], line 7\u001B[0m, in \u001B[0;36mSVM.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m----> 7\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/University/Year4/Final_Year_Project/Speech_Acts_Classification/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/University/Year4/Final_Year_Project/Speech_Acts_Classification/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/University/Year4/Final_Year_Project/Speech_Acts_Classification/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: linear(): argument 'input' (position 1) must be Tensor, not csr_matrix"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs.squeeze(), y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T16:14:30.821422Z",
     "start_time": "2024-02-08T16:14:30.550519Z"
    }
   },
   "id": "976bc3f0df295f84",
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2af8d1c5b7fc5b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Convert model predictions to labels\n",
    "def predictions_to_labels(predictions):\n",
    "    return torch.round(torch.sigmoid(predictions)).detach().numpy()\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    predicted_labels = predictions_to_labels(model(X))\n",
    "\n",
    "# Convert ground truth labels to numpy array\n",
    "true_labels = y.detach().numpy()\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='macro', zero_division=1)\n",
    "recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T16:14:30.836638Z",
     "start_time": "2024-02-08T16:14:30.827855Z"
    }
   },
   "id": "1d9aae0b8ac48cfd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-08T16:14:30.833570Z"
    }
   },
   "id": "d7d6876bbb90ad5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Decoding and evaluating with classification report"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1802b38604ed2f1b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def decode_labels(encoded_labels):\n",
    "    return label_encoder.inverse_transform(encoded_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T16:14:30.837826Z",
     "start_time": "2024-02-08T16:14:30.837717Z"
    }
   },
   "id": "286d206081139d7b",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
