{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T15:15:10.871023Z",
     "start_time": "2024-03-29T15:15:10.867216Z"
    }
   },
   "id": "initial_id",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Read data from Excel file\n",
    "df = pd.read_excel(\"../data/adjusted-labels-multiclass.xlsx\")\n",
    "\n",
    "# Extract sentences and labels\n",
    "sentences = df['Sentence'].tolist()\n",
    "labels = df.drop(columns=['Sentence']).values.tolist()\n",
    "\n",
    "# TF-IDF tokenization\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(sentences).toarray()\n",
    "\n",
    "# Convert labels to tensors\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T15:15:10.943455Z",
     "start_time": "2024-03-29T15:15:10.939481Z"
    }
   },
   "id": "6922958c251bbf85",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                            Sentence  \\\n0                                    this is Charlie   \n1                                         Roger over   \n2  Bravo I didn't find anything relevant just abo...   \n3  nothing really relevant just saying its open I...   \n4  Charlie I've got advertisement feature for the...   \n\n                              Labels  \n0  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n1  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n2  [1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0]  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n4  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence</th>\n      <th>Labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>this is Charlie</td>\n      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Roger over</td>\n      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Bravo I didn't find anything relevant just abo...</td>\n      <td>[1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>nothing really relevant just saying its open I...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Charlie I've got advertisement feature for the...</td>\n      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a data frame that has both the sentences and labels\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T15:15:12.138316Z",
     "start_time": "2024-03-29T15:15:12.126665Z"
    }
   },
   "id": "8867509aecdd77a2",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels_tensor, test_size=0.2, random_state=47)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "train_inputs = torch.tensor(X_train, dtype=torch.float32)\n",
    "test_inputs = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "train_labels = y_train\n",
    "test_labels = y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T15:15:10.955590Z",
     "start_time": "2024-03-29T15:15:10.950601Z"
    }
   },
   "id": "820a057cb1c4c186",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "BATCH = 32\n",
    "LR = 0.01\n",
    "EPOCHS = 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T15:15:12.122172Z",
     "start_time": "2024-03-29T15:15:10.961687Z"
    }
   },
   "id": "5a9f4b7eb81d38e1",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create DataLoader for training and test data\n",
    "train_dataset = TensorDataset(train_inputs, train_labels)\n",
    "test_dataset = TensorDataset(test_inputs, test_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T15:15:12.149561Z",
     "start_time": "2024-03-29T15:15:12.140995Z"
    }
   },
   "id": "2d4386d57a941666",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define your BERT-based model\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, input_size, num_labels):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(input_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        logits = self.fc(self.dropout(input_ids))\n",
    "        # return logits\n",
    "        probabilities = self.sigmoid(logits)  # Apply sigmoid activation\n",
    "        return probabilities"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T15:15:13.791107Z",
     "start_time": "2024-03-29T15:15:12.156909Z"
    }
   },
   "id": "4e37976dfbec2c3c",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load pre-trained BERT model\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Instantiate the BERT classifier model\n",
    "input_size = X_train.shape[1]\n",
    "# num_labels = len(labels[0])  # Number of labels\n",
    "num_labels = 11\n",
    "model = BERTClassifier(bert_model, input_size, num_labels)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T15:15:13.802417Z",
     "start_time": "2024-03-29T15:15:13.795412Z"
    }
   },
   "id": "e11be1628dd0f08c",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Training loop\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "avg_train_loss = 0\n",
    "\n",
    "num_epochs = EPOCHS\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        inputs, labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(inputs)\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    if (epoch+1) % 10 == 0:\n",
    "      print(f'Epoch {epoch+1}/{num_epochs}, Average Training Loss: {avg_train_loss}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T15:15:13.811193Z",
     "start_time": "2024-03-29T15:15:13.805759Z"
    }
   },
   "id": "acff4415552f99cf",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        inputs, labels = tuple(t.to(device) for t in batch)\n",
    "        logits = model(inputs)\n",
    "        test_loss += criterion(logits, labels).item()\n",
    "\n",
    "        y_true.extend(labels.cpu().detach().numpy())\n",
    "        y_pred.extend(torch.sigmoid(logits).cpu().detach().numpy())\n",
    "\n",
    "avg_test_loss = test_loss / len(test_dataloader)\n",
    "\n",
    "print(f'Average Training Loss: {avg_train_loss}')\n",
    "print(f'Average Test Loss: {avg_test_loss}')\n",
    "print(\"\")\n",
    "\n",
    "# Convert predictions and labels to numpy arrays\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, (y_pred >= 0.5))\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Print classification report\n",
    "y_pred[y_pred >= 0.5] = 1\n",
    "y_pred[y_pred < 0.5] = 0\n",
    "print(\"Classification Report\")\n",
    "print(f\"Using BCE Loss, Adam - Learning Rate {LR}, Epochs {EPOCHS}, Batch {BATCH}\")\n",
    "print(classification_report(y_true, y_pred, target_names=df.columns[1:]))\n",
    "\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'bert_multi_label_model.pth')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d560f122973a4455"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
